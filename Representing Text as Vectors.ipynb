{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "627dd5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10de8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "249d848c",
   "metadata": {},
   "source": [
    "### Bag of Words Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "697a1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['this is a sample sample sentence', 'this sentence is another example', 'another example sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c55d91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73acf492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>another</th>\n",
       "      <th>example</th>\n",
       "      <th>is</th>\n",
       "      <th>sample</th>\n",
       "      <th>sentence</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   another  example  is  sample  sentence  this\n",
       "0        0        0   1       2         1     1\n",
       "1        1        1   1       0         1     1\n",
       "2        1        1   0       0         1     0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bow.toarray(), columns=vectorizer.get_feature_names_out() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f981228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 2 1 1]\n",
      " [1 1 1 0 1 1]\n",
      " [1 1 0 0 1 0]]\n",
      "['another' 'example' 'is' 'sample' 'sentence' 'this']\n"
     ]
    }
   ],
   "source": [
    "print(bow.toarray())\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f51727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus each sentence has been converted into a vector\n",
    "\n",
    "# 'this is a sample sample sentence' => [0, 0, 1, 2, 1, 1]\n",
    "# 'this sentence is another example' => [1, 1, 1, 0, 1, 1]\n",
    "# 'another example sentence' => [1, 1, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d09f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe6814e3",
   "metadata": {},
   "source": [
    "### One Hot Encoding (word level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['this is a sample sample sentence', 'this sentence is another example', 'another example sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "336078d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = sorted(set(\" \".join(sentences).split()))\n",
    "# word_list = [sentence.split() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49d582d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'another', 'example', 'is', 'sample', 'sentence', 'this']\n",
      "Sentence 1\n",
      "       Word  x0_a  x0_another  x0_example  x0_is  x0_sample  x0_sentence  \\\n",
      "0      this   0.0         0.0         0.0    0.0        0.0          0.0   \n",
      "1        is   0.0         0.0         0.0    1.0        0.0          0.0   \n",
      "2         a   1.0         0.0         0.0    0.0        0.0          0.0   \n",
      "3    sample   0.0         0.0         0.0    0.0        1.0          0.0   \n",
      "4    sample   0.0         0.0         0.0    0.0        1.0          0.0   \n",
      "5  sentence   0.0         0.0         0.0    0.0        0.0          1.0   \n",
      "\n",
      "   x0_this  \n",
      "0      1.0  \n",
      "1      0.0  \n",
      "2      0.0  \n",
      "3      0.0  \n",
      "4      0.0  \n",
      "5      0.0  \n",
      "Sentence 2\n",
      "       Word  x0_a  x0_another  x0_example  x0_is  x0_sample  x0_sentence  \\\n",
      "0      this   0.0         0.0         0.0    0.0        0.0          0.0   \n",
      "1  sentence   0.0         0.0         0.0    0.0        0.0          1.0   \n",
      "2        is   0.0         0.0         0.0    1.0        0.0          0.0   \n",
      "3   another   0.0         1.0         0.0    0.0        0.0          0.0   \n",
      "4   example   0.0         0.0         1.0    0.0        0.0          0.0   \n",
      "\n",
      "   x0_this  \n",
      "0      1.0  \n",
      "1      0.0  \n",
      "2      0.0  \n",
      "3      0.0  \n",
      "4      0.0  \n",
      "Sentence 3\n",
      "       Word  x0_a  x0_another  x0_example  x0_is  x0_sample  x0_sentence  \\\n",
      "0   another   0.0         1.0         0.0    0.0        0.0          0.0   \n",
      "1   example   0.0         0.0         1.0    0.0        0.0          0.0   \n",
      "2  sentence   0.0         0.0         0.0    0.0        0.0          1.0   \n",
      "\n",
      "   x0_this  \n",
      "0      0.0  \n",
      "1      0.0  \n",
      "2      0.0  \n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "encoder.fit([[word] for word in unique_words])\n",
    "\n",
    "print(unique_words)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    words = sentence.split()\n",
    "    encoded = encoder.transform([[word] for word in words])\n",
    "    print(f\"Sentence {i+1}\")\n",
    "    #print(encoded)\n",
    "    df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out())\n",
    "    df.insert(0, \"Word\", words)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this => [0, 0, 0, 0, 0, 0, 1]\n",
    "# another => [0, 1, 0, 0, 0, 0, 0]\n",
    "# sentence => [0, 0, 0, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc7300",
   "metadata": {},
   "source": [
    "Conceptually, Bag of Words representation can be viewed as  the summation of one hot vectors per word in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8a6a6",
   "metadata": {},
   "source": [
    "We can one vector for the entire sentence (hence each sentence is 2d), or one vector for each word in a sentence (hence each sentence is 3d) The first approach is used for classical ML models, whereas second approach for Deep Learning models like CNN, RNN, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad6fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentence level one hot vs token level one hot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
